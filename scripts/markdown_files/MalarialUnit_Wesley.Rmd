---
title: "SpatioTemporal"
author: "Wesley Halstead"
date: "`r Sys.Date()`"
output: html_document
---

```{r}
library('dplyr')
library('ggplot2')
library('fields')
library('sf')
library('RColorBrewer')
library('CARBayesST')
library('spdep')
library('CARBayes')
```

### Read in Data
I went with the "pf" data rather than the "pv" data; even though the pv data is more temporally variable, the case numbers are way lower (average of like 2-3 cases per year).
Also this is just a test of the methods on Nigeria but I downloaded a few countries

```{r}
#malaria csv
mal <- read.csv("../../data/WestAfrica.csv")

#areal unit boundaries
boundaries <- st_read("../../data/NG_Admin/nga_admbnda_adm1_osgof_20161215.shp")
boundaries <- boundaries[,c("admin0Name", "admin1Name", "geometry")]

#spelling corrections
boundaries[which(boundaries$admin1Name=="Nasarawa"),]$admin1Name <- "Nassarawa"
boundaries[which(boundaries$admin1Name=="Federal Capital Territory"),]$admin1Name <- "Abuja"

head(mal)
```

```{r}
#check boundaries
temp <- filter(mal, National.Unit == "Nigeria" & Metric == "Mortality Rate" & Year == 2022)

temp2 <- inner_join(boundaries, temp, c("admin1Name" = "Name"))

#Pal <- colorRampPalette(rev(RColorBrewer::brewer.pal(3, "YlGnBu")))
Pal <- colorRampPalette(brewer.pal(3, "YlOrRd"))
temp2$Col <- Pal(10)[as.numeric(cut(temp2$Value,breaks = 10))]

plot(st_geometry(temp2), col=temp2$Col)
```

```{r}
library(tmap)
temp3 <- filter(mal, National.Unit == "Nigeria" & Metric == "Mortality Rate")
temp3 <- inner_join(boundaries, temp3, c("admin1Name" = "Name"))

# map
#legend_title = expression("Cumulative Cases per 100,000 Population")
tm_shape(temp3) +
  tm_fill("Value", palette = magma(256), style ="cont", 
          legend.hist=FALSE, legend.is.portrait=FALSE, fig.dim = c(5, 8)) +
  tm_facets(by = "Year", ncol = 4) +
  tm_borders(col = "white", lwd = .05)  + # add borders +
  tm_layout(bg.color = "white", # change background colour
            legend.outside = TRUE, # legend outside
            legend.outside.position = "bottom",
            legend.stack = "horizontal",
            legend.title.size = 2,
            legend.width = 1,
            legend.height = 1,
            panel.label.size = 3) 
```



```{r}
t1 <- filter(temp3, National.Unit == "Nigeria" & Metric == "Mortality Rate" & Year == 2010)
t2 <- filter(temp3, National.Unit == "Nigeria" & Metric == "Mortality Rate" & Year == 2014)
t3 <- filter(temp3, National.Unit == "Nigeria" & Metric == "Mortality Rate" & Year == 2018)
t4 <- filter(temp3, National.Unit == "Nigeria" & Metric == "Mortality Rate" & Year == 2022)

par(mfrow=c(2,2), mar=c(2,2,2,2))
plot(st_geometry(t1), col=Pal(10)[as.numeric(cut(t1$Value,breaks = 10))], main="2010")
plot(st_geometry(t2), col=Pal(10)[as.numeric(cut(t2$Value,breaks = 10))], main="2014")
plot(st_geometry(t3), col=Pal(10)[as.numeric(cut(t3$Value,breaks = 10))], main="2018")
plot(st_geometry(t4), col=Pal(10)[as.numeric(cut(t4$Value,breaks = 10))], main="2022")
```



```{r}
##Changed this to actually just look at incidence rates - Wesley
## Honestly, I think you might be able to just straight up do this as a normal distribution
IR <- mal$Value[mal$Metric == 'Incidence Rate']

hist(IR)

plot(sort(IR), qpois(ppoints(871), mean(IR)))

qqnorm(IR)
```



```{r}
#temporal analysis

### you cannot sum the values of rates to get an overall rate. This depends on the population as well - Wesley

### changing this a bit to make it a by region by year thing
### Just plotting a couple of the values
total_count <- mal %>% 
  filter(Metric == 'Incidence Rate', Name %in% c('Kano', 'Lagos','Katsina')) 

ggplot(total_count,
       aes(x = Year,
           y = Value,
           col = Name))+
  geom_line()+
  scale_x_continuous(breaks = 2010:2022)
```

* start with univariate analysis (ie, analysis over the aggregate of time and space, so no spatial or temporal dimension). the idea is just to study the data big-picture
* then analyze the data from each dimension individually (ie spatial analysis and time-series analysis)
* initially model as a Poisson (can also use a negative Binomial)

* a possible model setup could look something like this (just a suggested framework, we can change these parameters):

$$
Y_{i,t} \sim Poisson(E_i\exp(\mu_{i,t})) \\
\mu_{i,t} = \alpha + \beta x_i+ \nu_i + \omega_t \\
\nu_i \sim CAR(\sigma^2_v)

$$

here, $x_i$ is the spatial covariate, $\nu_i$ is the spatial random effect and $\omega_t$ is the temporal random effect.  
CAR model might not be appropriate in this specific context because Malaria is not contagious. Maybe model the spatial random effect using some other distribution.

Essentially, in order to do this right, I think I need total counts in order to do this properly. We derive these using the count and incidence rate introduced here. See pg.217 of the Handbook of Spatial Statistics
```{r}
#Malaria count data
malCount <- read.csv('../../data/Nigeria_Counts.csv')
hist(malCount$Value)
```
What do these count data look like by year?
```{r}
#check boundaries
temp <- filter(malCount, Year == 2022)

temp2 <- inner_join(boundaries, temp, c("admin1Name" = "Name"))

#Pal <- colorRampPalette(rev(RColorBrewer::brewer.pal(3, "YlGnBu")))
Pal <- colorRampPalette(brewer.pal(3, "YlOrRd"))
temp2$Col <- Pal(10)[as.numeric(cut(temp2$Value,breaks = 10))]

plot(st_geometry(temp2), col=temp2$Col)
```
```{r}
temp3 <- inner_join(boundaries, malCount, c("admin1Name" = "Name"))

t1 <- filter(temp3, Year == 2010)
t2 <- filter(temp3, Year == 2014)
t3 <- filter(temp3, Year == 2018)
t4 <- filter(temp3, Year == 2022)

Pal <- colorRampPalette(brewer.pal(3, "YlOrRd"))

par(mfrow=c(2,2), mar=c(2,2,2,2))
plot(st_geometry(t1), col=Pal(10)[as.numeric(cut(t1$Value,breaks = 10))], main="2010")
plot(st_geometry(t2), col=Pal(10)[as.numeric(cut(t2$Value,breaks = 10))], main="2014")
plot(st_geometry(t3), col=Pal(10)[as.numeric(cut(t3$Value,breaks = 10))], main="2018")
plot(st_geometry(t4), col=Pal(10)[as.numeric(cut(t4$Value,breaks = 10))], main="2022")
```



Calculating expected number under constant value
$$
\text{Rate per 1000} = \frac{\text{Total Infections}}{\text{Population}/1000} \\
\Rightarrow
\frac{1000 \times \text{Total Infections}}{\text{Rate per 1000} } = \text{Population}
$$


```{r}
malPop <- filter(mal, National.Unit == 'Nigeria' & Metric == 'Incidence Rate') %>%
  inner_join(malCount, by = join_by(Year == Year, Name == Name)) %>%
  rename(Observed = Value.y, Rate = Value.x) %>%
  mutate(Pop = 1000 * Observed/ Rate) %>%
  mutate(Expected = Pop * sum(Observed)/sum(Pop))
```

Plot populations
```{r}
ggplot(malPop,
       aes(x = Year,
           y = Pop,
           col = Name))+
  geom_line()+
  scale_x_continuous(breaks = 2010:2022)
```


Going to check expected values and population counts now

This one here is population counts for 2022
```{r}
#check boundaries
temp <- filter(malPop, Year == 2022)

temp2 <- inner_join(boundaries, temp, c("admin1Name" = "Name"))

#Pal <- colorRampPalette(rev(RColorBrewer::brewer.pal(3, "YlGnBu")))
Pal <- colorRampPalette(brewer.pal(3, "YlOrRd"))
temp2$Col <- Pal(10)[as.numeric(cut(temp2$Pop,breaks = 10))]

plot(st_geometry(temp2), col=temp2$Col)


temp4 <- inner_join(malPop, boundaries, c("Name" = "admin1Name")) %>%
  filter(Year == 2022) %>%
  st_as_sf()

temp4$Col <- Pal(10)[as.numeric(cut(temp4$Pop,breaks = 10))]

plot(st_geometry(temp4), col=temp4$Col)
```


This one here is expected counts
```{r}
#check boundaries
temp <- filter(malPop, Year == 2022)

temp2 <- inner_join(boundaries, temp, c("admin1Name" = "Name"))

#Pal <- colorRampPalette(rev(RColorBrewer::brewer.pal(3, "YlGnBu")))
Pal <- colorRampPalette(brewer.pal(3, "YlOrRd"))
temp2$Col <- Pal(10)[as.numeric(cut(temp2$Expected,breaks = 10))]

plot(st_geometry(temp2), col=temp2$Col)
```

Plot observed minus expected values (Blue is below expectation and red is above expectation)
I believe this plot justifies some use of spatial modeling.
```{r}
#check boundaries
temp <- filter(malPop, Year == 2022)

temp2 <- inner_join(boundaries, temp, c("admin1Name" = "Name"))

#Pal <- colorRampPalette(rev(RColorBrewer::brewer.pal(3, "YlGnBu")))
Pal <- colorRampPalette(brewer.pal(3, "RdBu"))
temp2$Col <- Pal(10)[as.numeric(cut(-temp2$Observed + temp2$Expected,breaks = 10))]

plot(st_geometry(temp2), col=temp2$Col)
```

Plot Expected Versus Observed Values
```{r}
plot(malPop$Expected, malPop$Observed)
```

Fit GLM. This is difficult since there is this constant value within. We use the offset term in order to do this.
```{r}
GLM1 <- glm(round(malPop$Observed) ~  offset(log(round(malPop$Expected))) +  malPop$Pop,
              family = poisson)

summary(GLM1)
```


Plotting Residuals (Blue $\Rightarrow$ Observed > Expected, Red $\Rightarrow$ Observed < Expected)
```{r}
fit_resid <- malPop$Observed - GLM1$fitted.values

t1 <- mutate(malPop, resid = Observed - GLM1$fitted.values)%>% 
  filter(Year == 2010) %>%
  inner_join(boundaries, join_by(Name == admin1Name)) %>%
  dplyr::select(resid, geometry) %>%
  st_as_sf()

t2 <- mutate(malPop, resid = Observed - GLM1$fitted.values)%>% 
  filter(Year == 2014) %>%
  inner_join(boundaries, join_by(Name == admin1Name)) %>%
  dplyr::select(resid, geometry) %>%
  st_as_sf()

t3 <- mutate(malPop, resid = Observed - GLM1$fitted.values)%>% 
  filter(Year == 2018) %>%
  inner_join(boundaries, join_by(Name == admin1Name)) %>%
  dplyr::select(resid, geometry) %>%
  st_as_sf()

t4 <- mutate(malPop, resid = Observed - GLM1$fitted.values)%>% 
  filter(Year == 2022) %>%
  inner_join(boundaries, join_by(Name == admin1Name)) %>%
  dplyr::select(resid, geometry) %>%
  st_as_sf()


par(mfrow=c(2,2), mar=c(2,2,2,2))
plot(st_geometry(t1), col=Pal(10)[as.numeric(cut(-t1$resid,breaks = 10))], main="2010")
plot(st_geometry(t2), col=Pal(10)[as.numeric(cut(-t2$resid,breaks = 10))], main="2014")
plot(st_geometry(t3), col=Pal(10)[as.numeric(cut(-t3$resid,breaks = 10))], main="2018")
plot(st_geometry(t4), col=Pal(10)[as.numeric(cut(-t4$resid,breaks = 10))], main="2022")
```



Taking log of population to fit this particular GLM.
```{r}
GLM2 <- glm(round(malPop$Observed) ~  offset(log(round(malPop$Expected))) +  log(malPop$Pop),
              family = poisson)

summary(GLM2)
```

```{r}
fit_resid <- malPop$Observed - GLM2$fitted.values
fit_resid <- fit_resid[malPop$Year == 2022]

Pal <- colorRampPalette(brewer.pal(3, "RdBu"))
temp2$Col <- Pal(10)[as.numeric(cut(fit_resid,breaks = 10))]

plot(st_geometry(temp2), col=temp2$Col)
```

Moving into CAR model. Not sure, but I think I can fit this just with CARBayesST


Plotting the connected boundaries on a map
```{r}
cen <- boundaries %>% filter(admin0Name == 'Nigeria') %>% st_centroid()

A <- as.matrix(st_touches(boundaries))
m    <- rowSums(A)
adj  <- apply(A==1,1,which)
W<-as.matrix(A)
nb1<-mat2listw(W, style = 'B')

coords <- as.matrix(st_coordinates(cen$geometry))

plot(st_geometry(boundaries))
plot.listw(nb1,coords=coords,add=T,col=4,lwd=1.5)
```
This is non-spatial Bayes GLM:
```{r}
formula <- round(malPop$Observed) ~  offset(log(round(malPop$Expected))) +  malPop$Pop

n <- 50000


bGLM1 <- S.glm(formula = formula,
               family = 'poisson',
               n.sample = n,
               burnin = 0.5*n,
               prior.mean.beta = GLM1$coefficients)
bGLM1
```

This is not correct, there is a different way to construct this that I need to implement.
Looks like it may not be possible to do this with multiple samples across each region?
Possibly we can just aggregate regions since sums of poisson random variables are still poisson?
```{r}
temp <- filter(malPop, Year == 2022)

mat1 <- inner_join(temp,boundaries,join_by(Name == admin1Name)) %>% st_as_sf() %>% st_touches()
mat1 <- 1*as.matrix(mat1)



formula <- round(temp$Observed) ~  offset(log(round(temp$Expected))) +  temp$Pop


n = 10000
S.CARleroux(
  formula = formula,
  family = 'poisson',
  n.sample = n,
  burnin = 0.5*n,
  W = 1*mat1
)
```

All work done previously was done without the aggregate climate data. We are now going to attempt to use the features in that data frame in order to produce GLMs as seen above. We begin that below:

First start by merging our data frames:

```{r}
climate <- read.csv('../../data/Nigeria_Climate_Aggregate.csv')
malPop <- inner_join(malPop, climate, join_by(Name == name))
```



I came back to this later after working with the Bayesian models a bit more. Co-linearity between average_mean and average_max causes Bayesian estimates to not be consistent. We fix this here by removing the max value from our model.
```{r}

f1 <- round(Observed) ~ offset(log(round(Expected))) + scale(Pop) + scale(average_min) + scale(average_mean) + scale(average_precipitation)

GLM1 <- glm(
 formula = f1,
  family = poisson,
  data = malPop
)

summary(GLM1)
```
Plotting residuals again now with climate data
```{r}
fit_resid <- malPop$Observed - GLM1$fitted.values

t1 <- mutate(malPop, resid = Observed - GLM1$fitted.values)%>% 
  filter(Year == 2010) %>%
  inner_join(boundaries, join_by(Name == admin1Name)) %>%
  dplyr::select(resid, geometry) %>%
  st_as_sf()

t2 <- mutate(malPop, resid = Observed - GLM1$fitted.values)%>% 
  filter(Year == 2014) %>%
  inner_join(boundaries, join_by(Name == admin1Name)) %>%
  dplyr::select(resid, geometry) %>%
  st_as_sf()

t3 <- mutate(malPop, resid = Observed - GLM1$fitted.values)%>% 
  filter(Year == 2018) %>%
  inner_join(boundaries, join_by(Name == admin1Name)) %>%
  dplyr::select(resid, geometry) %>%
  st_as_sf()

t4 <- mutate(malPop, resid = Observed - GLM1$fitted.values)%>% 
  filter(Year == 2022) %>%
  inner_join(boundaries, join_by(Name == admin1Name)) %>%
  dplyr::select(resid, geometry) %>%
  st_as_sf()


par(mfrow=c(2,2), mar=c(2,2,2,2))
plot(st_geometry(t1), col=Pal(10)[as.numeric(cut(-t1$resid,breaks = 10))], main="2010")
plot(st_geometry(t2), col=Pal(10)[as.numeric(cut(-t2$resid,breaks = 10))], main="2014")
plot(st_geometry(t3), col=Pal(10)[as.numeric(cut(-t3$resid,breaks = 10))], main="2018")
plot(st_geometry(t4), col=Pal(10)[as.numeric(cut(-t4$resid,breaks = 10))], main="2022")
```


Bayesian GLM

```{r}

n <- 50000

bGLM1 <- S.glm(formula = f1,
               data = malPop,
               family = 'poisson',
               n.sample = n,
               burnin = n*0.5)

bGLM1
```
Use CARBayes to fit a CAR model here. We use Leroux since it is the same parameterization used in the CARBayesST package that we will use later.

These have to be separately by year. We have the 2022 model here, but this code could be easily extended to loop through multiple years.

```{r}
n <- 500000

temp <- filter(malPop, Year == 2022)

mat1 <- inner_join(temp,boundaries,join_by(Name == admin1Name)) %>% st_as_sf() %>% st_touches()
mat1 <- 1*as.matrix(mat1)


bGLM2 <- S.CARleroux(formula = f1,
               data = temp,
               family = 'poisson',
               n.sample = n,
               burnin = n*0.5,
               thin = 2,
               W = mat1,
               prior.mean.beta = GLM1$coefficients,
               prior.var.beta = summary(GLM1)$coefficients[,2])

bGLM2
```

Plot convergence of Rho
```{r}


plot(
  1:250*500,
  (cumsum(bGLM2$samples$rho)/(1:125000))[seq(1,length(bGLM2$samples$rho),500)],
  col = 'black',
  type = 'l',
  ylab = 'Running Mean of Rho',
  xlab = 'Samples'
)
abline(h = 0.3203, lty = 2, col = 'red')

```


Spatial Temporal model here

```{r}

n <- 50000

temp <- arrange(malPop, Year)


temp2 <- temp %>% filter(Year == 2010)
mat1 <- inner_join(temp2,boundaries,join_by(Name == admin1Name)) %>% st_as_sf() %>% st_touches()
mat1 <- 1*as.matrix(mat1)


bGLM3 <- ST.CARanova(
  formula = f1,
  data = temp,
  family = 'poisson',
  n.sample = n,
  burnin = n*0.5,
  thin = 2,
  W = mat1,
  prior.mean.beta = GLM1$coefficients,
  prior.var.beta = summary(GLM1)$coefficients[,2],
  interaction = FALSE
  
)
  


bGLM3

```


```{r}





plot(
  1:250*50,
  (cumsum(bGLM3$samples$rho[,1])/(1:12500))[seq(1,length(bGLM3$samples$rho[,1]),50)],
  col = 'red',
  type = 'l',
  ylab = 'Running Mean of Rho.S',
  xlab = 'Samples',
  ylim = c(.2,.9)
)

lines(
  1:250*50,
  (cumsum(bGLM3$samples$rho[,2])/(1:12500))[seq(1,length(bGLM3$samples$rho[,2]),50)],
  col = 'blue',
  type = 'l'
)


abline(h = sum(bGLM3$samples$rho[,1])/12500, lty = 2, col = 'darkred')
abline(h = sum(bGLM3$samples$rho[,2])/12500, lty = 2, col = 'darkblue')

```